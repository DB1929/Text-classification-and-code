2	基于机器学习的文本分类方法
2.1	KNN分类方法
KNN是一种基于数据之间的距离来实现类别的判定的一种分类方法。它首先将数据分为两个部分，一部分是已经分类完的数据，已知数据类别数据，另一类则是用来进行测试的未分类数据。将距离作为一个分类的重要参考，未分类的数据与已分类数据的距离越近，就认为这个样本属于类数据的可能性就越高。分类的决策标准是先给定一个初始的K值，在被分类样本点的周围选取K个最相近的元素，计算其周围各种类别元素的数量，哪个元素的数量最多，则就将新的样本点分为哪一类。
将KNN分类方法简单概括为四个步骤：
（1）	将所有数据集分为训练数据集和测试数据集。
（2）	找出距离待分类样本周围最近的K个元素点。
（3）	统计计算这K个点中各类别元素出现的频率。
（4）	制定分类标准。距离作为样本点的一个属性，根据距离的大小计算各个类别的权重。最后加权求和，计算出加权平均数，样本的距离属性值哪个最大，就将样本分为哪一类。
2.2	 Naive Bayes文本分类方法
 方法主要是先计算每个类别出现的概率，输入训练样本之后，再计算得到关于样本类别的后验概率，根据分为正类和负类概率的大小来预测样本所属类别的分类方法。
2.3	SVM分类方法
简介：支持向量机SVM是一种基于监督学习的数据二分类方法。可以对线性可分的数据进行分类；对于低维线性不可分的数据，但是高维可分的数据，使用核函数的方法利用非线性映射将其映射到高维空间中进行分类；至于更加复杂的不可分数据，降低对分类平面的要求，加上一个惩罚因子，利用结构风险最小化理论，并且在特征空间构建最优超平面对数据进行分类。
